"""
The spm module provides basic functions for interfacing with matlab and spm to 
access spm tools.

these functions include 
    
    Realign: within-modality registration

    SliceTiming : correcting differences in image acquisition time between slices

    Coregister: between modality registration
    
    Normalize: non-linear warping to standard space

    Segment: bias correction, segmentation

"""
#from __future__ import with_statement

from nipype.interfaces.base import Bunch, CommandLine, Interface, setattr_on_read, InterfaceResult
from nipype.externals.pynifti import load
from nipype.interfaces.matlab import fltcols
import nipype.interfaces.matlab as matlab
from scipy.io import savemat
from glob import glob
import numpy as np
import os
from nipype.utils import InTemporaryDirectory

mlab = matlab.Matlab()

class SpmInfo(object):
    @setattr_on_read
    def spm_path(self):
        try:
            InTemporaryDirectory()
            mlab.run_matlab_script("""
spm_path = spm('dir');
fid = fopen('spm_path.txt', 'wt');
fprintf(fid, '%s', spm_path);
fclose(fid);
""")
            spm_path = file('spm_path.txt', 'rt').read()
            return spm_path
        except:
            print 'Failed to return spm path'
            return None
       


spm_info = SpmInfo()

def reformat_dict_for_savemat(contents):
    if type(contents) == type({}):
        newdict = {}
        for key,value in contents.items():
            if type(value) == type({}):
                if value == {} or value is None:
                    pass
                else:
                    newdict.update({key:format_dict(value)})
            else:
                newdict.update({key:value})
        return [newdict]

def generate_job(prefix,contents):
    """ Recursive function to generate spm job specification as a string
    
    Arguments:
    - `prefix`:
    - `contents`:
    """
    jobstring = ''
    if type(contents) == type([]):
        for i,value in enumerate(contents):
            newprefix = "%s(%d)" % (prefix,i+1)
            jobstring += generate_job(newprefix,value)
        return jobstring
    if type(contents) == type({}):
        for key,value in contents.items():
            newprefix = "%s.%s" % (prefix,key)
            jobstring += generate_job(newprefix,value)
        return jobstring
    if type(contents) == type(np.empty(1)):
        #Assumes list of filenames embedded in a numpy array
        jobstring += "%s = {...\n"%(prefix)
        for item in contents:
            jobstring += '\'%s\';...\n'%(item[0])
        jobstring += '};\n'
        return jobstring
    if type(contents) == type(''):
        jobstring += "%s = '%s';\n" % (prefix,contents)
        return jobstring
    jobstring += "%s = %s;\n" % (prefix,str(contents))
    return jobstring

def make_matlab_command(jobtype, jobname, contents, mfile=True,cwd='.'):
    """ generates a mfile to build job structure
    >>> import numpy as np
    >>> import nipype.interfaces.spm as spm
    >>> tmp = [{'estimate':{'files':np.array(['a.nii','b.nii']),'eoptions':{'interp':2},'roptions':{}}}]
    >>> spm.make_mfile('spatial','realign',tmp)
    """
    mscript = '% generated by nipype.interfaces.spm\n'
    mscript += "spm_defaults;\n\n"
    if mfile:
        mscript += generate_job('jobs{1}.%s{1}.%s{1}' % (jobtype,jobname) ,contents[0])
    else:
        jobdef = {'jobs':[{jobtype:[{jobname:reformat_dict_for_savemat(contents[0])}]}]}
        savemat(os.path.join(cwd,'pyjobs_%s.mat'%jobname), jobdef)
        mscript = "load pyjobs_%s;\n spm_jobman('run', jobs);\n" % jobname
    mscript += 'spm_jobman(\'run\',jobs);'
    return mlab.gen_matlab_command(mscript,cwd=cwd,script_name='pyscript_%s'%jobname)

def scans_for_fname(fname):
    img = load(fname)
    if len(img.get_shape()) == 3:
        scans = np.zeros((n_scans, 1), dtype=object)
        scans[0] = '%s,1'%(fname)
        return scans
    else:
        n_scans = img.get_shape()[3]
        scans = np.zeros((n_scans, 1), dtype=object)
        for sno in range(n_scans):
            scans[sno] = '%s,%d' % (fname, sno+1)
        return scans


def scans_for_fnames(fnames):
    n_sess = len(fnames)
    sess_scans = np.zeros((1,n_sess), dtype=object)
    for sess in range(n_sess):
        sess_scans[0,sess] = scans_for_fname(fnames[sess])
    return sess_scans


def fname_presuffix(fname, prefix='', suffix='', use_ext=True):
    pth, fname = os.path.split(fname)
    fname, ext = os.path.splitext(fname)
    if not use_ext:
        ext = ''
    return os.path.join(pth, prefix+fname+suffix+ext)


def fnames_presuffix(fnames, prefix='', suffix=''):
    f2 = []
    for fname in fnames:
        f2.append(fname_presuffix(fname, prefix, suffix))
    return f2


class Realign(CommandLine):
    """use spm_realign for estimating within modality
    rigid body alignment

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the Realign.inputs attributes
    see self.inputs_help() for a list of Realign.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_realign via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    Realign().inputs_help()

    To see output fields
    Realign().outputs_help()

    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_realign'
        
    def inputs_help(self):
        doc = """
            Optional Parameters
            -------------------
            (all default to None and are unset)

            infile : list
                list of filenames to realign
            write : bool
                if True updates headers and generates
                resliced files prepended with  'r'
                if False just updates header files
                (default == True, will reslice)
            quality : float
                0.1 = fastest, 1.0 = most precise
                (spm5 default = 0.9)
            fwhm : float
                full width half maximum gaussian kernel 
                used to smoth images before realigning
                (spm default = 5.0)
            separation : float
                separation in mm used to sample images
                (spm default = 4.0)
            register_to_mean: Bool
                rtm if True uses a two pass method
                realign -> calc mean -> realign all to mean
                (spm default = False)
            weight_img : file
                filename of weighting image
                if empty, no weighting 
                (spm default = None)
            wrap : list
                Check if interpolation should wrap in [x,y,z]
                (spm default [0,0,0])
            interp: float
                degree of b-spline used for interpolation
                (spm default = 2.0)
            write_which : list of len()==2
                if write is true, 
                [inputimgs, mean]
                [2,0] reslices all images, but not mean
                [2,1] reslices all images, and mean
                [1,0] reslices imgs 2:end, but not mean
                [0,1] doesnt reslice any but generates resliced mean
            write_interp: float
                degree of b-spline used for interpolation when
                writing resliced images
                (spm default = 4.0)
            write_wrap : list
                Check if interpolation should wrap in [x,y,z]
                (spm default [0,0,0])
            write_mask: bool
                if True, mask output image
                if False, do not mask
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
                        
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(infile=None,
                          write=True,
                          quality=None,
                          fwhm=None,
                          separation=None,
                          register_to_mean=None,
                          weight_img=None,
                          interp=None,
                          wrap=None,
                          write_which=None,
                          write_interp=None,
                          write_wrap=None,
                          write_mask=None,
                          flags=None)
        
    def _parseinputs(self):
        """validate spm realign options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'eoptions':{},'roptions':{}}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'flags':
                einputs.update(inputs[opt])
            if opt is 'infile':
                continue
            if opt is 'write':
                continue
            if opt is 'quality':
                einputs['eoptions'].update({'quality': float(inputs[opt])})
                continue
            if opt is 'fwhm':
                einputs['eoptions'].update({'fwhm': float(inputs[opt])})
                continue
            if opt is 'separation':
                einputs['eoptions'].update({'sep': float(inputs[opt])})
                continue
            if opt is 'register_to_mean':
                einputs['eoptions'].update({'rtm': int(inputs[opt])})
                continue
            if opt is 'weight_img':
                einputs['eoptions'].update({'weight': inputs[opt]})
                continue
            if opt is 'interp':
                einputs['eoptions'].update({'interp': float(inputs[opt])})
                continue
            if opt is 'wrap':
                if not len(inputs[opt]) == 3:
                    raise ValueError('wrap must have 3 elements')
                einputs['eoptions'].update({'wrap': inputs[opt]})
                continue
            if opt is 'write_which':
                if not len(inputs[opt]) == 2:
                    raise ValueError('write_which must have 2 elements')
                einputs['roptions'].update({'which': inputs[opt]})
                continue
            if opt is 'write_interp':
                einputs['roptions'].update({'interp': inputs[opt]})
                continue
            if opt is 'write_wrap':
                if not len(inputs[opt]) == 3:
                    raise ValueError('write_wrap must have 3 elements')
                einputs['roptions'].update({'wrap': inputs[opt]})
                continue
            if opt is 'write_mask':
                einputs['roptions'].update({'mask': int(inputs[opt])})
                continue
                
            print 'option %s not supported'%(opt)
        return einputs

    def outputs_help(self):
        doc = """
            Output files
            ------------
            (all default to None)

            realigned_files:
                list of realigned files
            mean_image:
                mean image file from the realignment process
            realignment_parameters: rp*.txt
                files containing the estimated translation and
                rotation parameters
            """
        print doc
        
    def _aggregate_outputs(self):
        outputs = Bunch(realigned_files=None,
                        realignment_parameters=None,
                        mean_image=None)
        outputs.mean_image = glob(fname_presuffix(self.inputs.infile,prefix='mean'))
        outputs.realigned_files = []
        outputs.realignment_parameters = []
        if type(self.inputs.infile) == type([]):
            filelist = self.inputs.infile
        else:
            filelist = [self.inputs.infile]
        for f in filelist:
            outputs.realigned_files.append(glob(fname_presuffix(f,prefix='r',suffix='.nii',use_ext=False)).pop())
            outputs.realignment_parameters.append(glob(fname_presuffix(f,prefix='rp_',suffix='.txt',use_ext=False)).pop())
        return outputs
        
    def run(self, mfile=True):
        self._compile_command(mfile)
        returncode,out,err = self._runner(cwd=self.inputs.get('cwd','.'))
        if  'PyScriptException' in err:
            returncode = 1
            outputs = None
        else:
            outputs = self._aggregate_outputs()

        return InterfaceResult(runtime=Bunch(cmdline=self.cmdline,
                                             returncode=returncode,
                                             stdout=out,stderr=err),
                               outputs=outputs,
                               interface=self.copy())
                
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        if self.inputs.write:
            jobtype = 'estwrite'
        else:
            jobtype = 'estimate'
        valid_inputs = self._parseinputs()
        if type(self.inputs.infile) == type([]):
            sess_scans = scans_for_fnames(self.inputs.infile)
        else:
            sess_scans = scans_for_fname(self.inputs.infile)
        # create job structure form valid options and data
        tmp = [{'%s'%(jobtype):{'data':sess_scans,
                                'eoptions':valid_inputs['eoptions'],
                                'roptions':valid_inputs['roptions']
                                }}]
        self.cmdline = make_matlab_command('spatial','realign',tmp,mfile,self.inputs.get('cwd','.'))
        return self.cmdline

class Coregister(CommandLine):
    """use spm_coreg for estimating cross-modality
    rigid body alignment

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the Coregister.inputs attributes
    see self.inputs_help() for a list of Coregister.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_coreg via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    Coregister().inputs_help()

    To see output fields
    Coregister().outputs_help()

    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_coreg'
        
    def inputs_help(self):
        doc = """
            Mandatory Parameters
            -------------------- 
            target : string
                filename of nifti image to coregister to
            source : string
                filename of nifti image to coregister to the reference

            Optional Parameters
            -------------------
            (all default to None and are unset)

            infile : list
                list of filenames to apply the estimated rigid body
                transform from source to target 
            write : bool
                if True updates headers and generates resliced files
                prepended with  'r' if False just updates header files
                (default == True, will reslice) 
            cost_function: string
                maximise   or   minimise   some   objective
                function. For inter-modal    registration,    use
                Mutual   Information (mi), Normalised Mutual
                Information (nmi), or  Entropy  Correlation
                Coefficient (ecc). For within modality, you could also
                use Normalised Cross Correlation (ncc).
                (spm default = mi)
            separation : float
                separation in mm used to sample images
                (spm default = 4.0)
            tolerance: list of 12 floats
                The   accuracy  for  each  parameter.  Iterations
                stop  when differences  between  successive  estimates
                are less than the required tolerance for each of the
                12 parameters.
            fwhm : float
                full width half maximum gaussian kernel 
                used to smoth images before coregistering
                (spm default = 5.0)
            write_interp: int
                degree of b-spline used for interpolation when
                writing resliced images (0 - Nearest neighbor, 1 - 
                Trilinear, 2-7 - degree of b-spline)
                (spm default = 0 - Nearest Neighbor)
            write_wrap : list
                Check if interpolation should wrap in [x,y,z]
                (spm default [0,0,0])
            write_mask: bool
                if True, mask output image
                if False, do not mask
                (spm default = False)
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
                        
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(target=None,
                            source=None,
                            infile=None,
                            write=True,
                            cost_function=None,
                            separation=None,
                            tolerance=None,
                            fwhm=None,
                            write_interp=None,
                            write_wrap=None,
                            write_mask=None,
                            flags=None)
        
    def _parseinputs(self):
        """validate spm coregister options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'eoptions':{},'roptions':{}}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'target':
                continue
            if opt is 'source':
                continue
            if opt is 'infile':
                continue
            if opt is 'write':
                continue
            if opt is 'cost_function':
                einputs['eoptions'].update({'cost_fun': inputs[opt]})
                continue
            if opt is 'separation':
                einputs['eoptions'].update({'sep': float(inputs[opt])})
                continue
            if opt is 'tolerance':
                einputs['eoptions'].update({'tol': inputs[opt]})
                continue
            if opt is 'fwhm':
                einputs['eoptions'].update({'fwhm': float(inputs[opt])})
                continue
            if opt is 'write_interp':
                einputs['roptions'].update({'interp': inputs[opt]})
                continue
            if opt is 'write_wrap':
                if not len(inputs[opt]) == 3:
                    raise ValueError('write_wrap must have 3 elements')
                einputs['roptions'].update({'wrap': inputs[opt]})
                continue
            if opt is 'write_mask':
                einputs['roptions'].update({'mask': int(inputs[opt])})
                continue
            if opt is 'flags':
                einputs.update(inputs[opt])
                continue
            print 'option %s not supported'%(opt)
        return einputs

    def outputs_help(self):
        doc = """
            Output files
            ------------
            (all default to None)

            coregistered_source:
                coregistered source file
            coregistered_files:
                coregistered files corresponding to inputs.infile
            """
        print doc
        
    def _aggregate_outputs(self):
        outputs = Bunch(coregistered_source=None,
                        coregistered_files=None)
        outputs.coregistered_source = [glob(fname_presuffix(self.inputs.source,prefix='r',suffix='.nii',use_ext=False)).pop()]
        outputs.coregistered_files = []
        if type(self.inputs.infile) == type([]):
            filelist = self.inputs.infile
        else:
            filelist = [self.inputs.infile]
        for f in filelist:
            outputs.coregistered_files.append(glob(fname_presuffix(f,prefix='r',suffix='.nii',use_ext=False)).pop())
        return outputs
        
    def run(self, mfile=True):
        self._compile_command(mfile)
        returncode,out,err = self._runner(cwd=self.inputs.get('cwd','.'))
        if  'PyScriptException' in err:
            returncode = 1
            outputs = None
        else:
            outputs = self._aggregate_outputs()

        return InterfaceResult(provenance=Bunch(cmdline=self.cmdline,
                                                returncode=returncode,
                                                stdout=out,stderr=err),
                               outputs=outputs,
                               interface=self.copy())
        
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        if self.inputs.write:
            jobtype = 'estwrite'
        else:
            jobtype = 'estimate'
        valid_inputs = self._parseinputs()
        if type(self.inputs.infile) == type([]):
            sess_scans = scans_for_fnames(self.inputs.infile)
        else:
            sess_scans = scans_for_fname(self.inputs.infile)

        
        # create job structure form valid options and data
        tmp = [{'%s'%(jobtype):{'ref':self.inputs.target,
                                'source':self.inputs.source,
                                'other':sess_scans,
                                'eoptions':valid_inputs['eoptions'],
                                'roptions':valid_inputs['roptions']
                                }}]
        self.cmdline = make_matlab_command('spatial','coreg',tmp,mfile,cwd=self.inputs.get('cwd','.'))
        return self.cmdline
        
class Normalize(CommandLine):
    """use spm_normalise for warping an image to a template

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the Normalize.inputs attributes
    see self.inputs_help() for a list of Normalize.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_normalise via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    Normalize().inputs_help()


    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_normalise'

    def inputs_help(self):
        doc = """
            Mandatory Parameters
            --------------------
            template : string
                filename of nifti image to normalize to
            source : string
                filename of nifti image to normalize

            Optional Parameters
            -------------------
            (all default to None and are unset)

            infile : list
                list of filenames to apply the estimated normalization
            write : bool
                if True updates headers and generates resliced files
                prepended with  'r' if False just updates header files
                (default == True, will reslice)
            source_weight : string
                name of weighting image for source
            template_weight : string
                name of weighting image for template
            source_image_smoothing: float
            template_image_smoothing: float
            affine_regularization_type: string
                ICBM space template (mni), average sized template
                (size), no regularization (none)
            DCT_period_cutoff: int
                Cutoff  of  DCT  bases. Only DCT bases of periods
                longer than cutoff  are  used to describe the warps. 
                spm default = 25
            nonlinear_iterations: int
                Number of iterations of nonlinear warping
                spm default = 16
            nonlinear_regularization: float
                min = 0  max = 1
                spm default = 1
            write_preserve: int
                Preserve  Concentrations (0): Spatially normalised images
                are not "modulated".  The  warped  images preserve the
                intensities of the original images. Preserve  Total (1):
                Spatially normalised images are "modulated" in  order
                to  preserve  the  total  amount  of signal in the
                images.   Areas   that   are   expanded  during
                warping  are correspondingly reduced in intensity.
                spm default = 0 
            write_bounding_box: 6-element list
            write_voxel_sizes: 3-element list
            write_interp: int
                degree of b-spline used for interpolation when
                writing resliced images (0 - Nearest neighbor, 1 - 
                Trilinear, 2-7 - degree of b-spline)
                (spm default = 0 - Nearest Neighbor)
            write_wrap : list
                Check if interpolation should wrap in [x,y,z]
                (spm default [0,0,0])
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(template=None,
                            source=None,
                            infile=None,
                            write=True,
                            source_weight=None,
                            template_weight=None,
                            source_image_smoothing=None,
                            template_image_smoothing=None,
                            affine_regularization_type=None,
                            DCT_period_cutoff=None,
                            nonlinear_iterations=None,
                            nonlinear_regularization=None,
                            write_preserve=None,
                            write_bounding_box=None,
                            write_voxel_sizes=None,
                            write_interp=None,
                            write_wrap=None,
                            flags=None)
        
    def _parseinputs(self):
        """validate spm normalize options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'subj':{},'eoptions':{},'roptions':{}}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'template':
                einputs['eoptions'].update({'template': inputs[opt]})
                continue
            if opt is 'source':
                einputs['subj'].update({'source': inputs[opt]})
                continue
            if opt is 'infile':
                continue
            if opt is 'write':
                continue
            if opt is 'source_weight':
                einputs['subj'].update({'wtsrc': inputs[opt]})
                continue
            if opt is 'template_weight':
                einputs['eoptions'].update({'weight': inputs[opt]})
                continue
            if opt is 'source_image_smoothing':
                einputs['eoptions'].update({'smosrc': float(inputs[opt])})
                continue
            if opt is 'template_image_smoothing':
                einputs['eoptions'].update({'smoref': float(inputs[opt])})
                continue
            if opt is 'affine_regularization_type':
                einputs['eoptions'].update({'regtype': inputs[opt]})
                continue
            if opt is 'DCT_period_cutoff':
                einputs['eoptions'].update({'cutoff': inputs[opt]})
                continue
            if opt is 'nonlinear_iterations':
                einputs['eoptions'].update({'nits': inputs[opt]})
                continue
            if opt is 'nonlinear_regularization':
                einputs['eoptions'].update({'reg': float(inputs[opt])})
                continue
            if opt is 'write_preserve':
                einputs['roptions'].update({'preserve': inputs[opt]})
                continue
            if opt is 'write_bounding_box':
                einputs['roptions'].update({'bb': inputs[opt]})
                continue
            if opt is 'write_voxel_sizes':
                einputs['roptions'].update({'vox': inputs[opt]})
                continue
            if opt is 'write_interp':
                einputs['roptions'].update({'interp': inputs[opt]})
                continue
            if opt is 'write_wrap':
                if not len(inputs[opt]) == 3:
                    raise ValueError('write_wrap must have 3 elements')
                einputs['roptions'].update({'wrap': inputs[opt]})
                continue
            if opt is 'flags':
                einputs.update(inputs[opt])
                continue
            print 'option %s not supported'%(opt)
        return einputs

    def run(self, mfile=True):
        
        job = self._compile_command(mfile)

        if mfile:
            out, cmdline = mlab.run_matlab_script(job, 
                                                  script_name='pyscript_spmnormalize')
        else:
            out = run_jobdef(job)
            cmdline = ''
            
        output = InterfaceResult(provenance=Bunch(returncode=returncode,
                                                  stdout=out,stderr=err),
                                 outputs=self._aggregate_outputs(),
                                 interface=self.copy())
        return output
        
        
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        if self.inputs.write:
            jobtype = 'estwrite'
        else:
            jobtype = 'est'
        valid_inputs = self._parseinputs()
        if type(self.inputs.infile) == type([]):
            sess_scans = scans_for_fnames(self.inputs.infile)
        else:
            sess_scans = scans_for_fname(self.inputs.infile)

        valid_inputs['subj']['resample'] = sess_scans
        
        # create job structure form valid options and data
        tmp = [{'%s'%(jobtype):{'subj':valid_inputs['subj'],
                                'eoptions':valid_inputs['eoptions'],
                                'roptions':valid_inputs['roptions']
                                }}]
        if mfile:
            return make_mfile('spatial','normalise',tmp)
        else:
            return make_job('spatial','normalise',tmp)

class Smooth(CommandLine):
    """use spm_smooth for 3D Gaussian smoothing of image volumes.

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the Smooth.inputs attributes
    see self.inputs_help() for a list of Smooth.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_smooth via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    Smooth().inputs_help()


    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_smooth'

    def inputs_help(self):
        doc = """
            Mandatory Parameters
            --------------------
            infile : list
                list of filenames to apply smoothing

            Optional Parameters
            -------------------
            (all default to None and are unset)

            fwhm : 3-list
                list of fwhm for each dimension
            data_type : int
                spm default = 0
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(infile=None,
                            fwhm=None,
                            flags=None)
        
    def _parseinputs(self):
        """validate spm normalize options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'fwhm':[],'dtype':0}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'infile':
                continue
            if opt is 'fwhm':
                einputs['fwhm'] = inputs[opt]
                continue
            if opt is 'data_type':
                einputs['dtype'] = inputs[opt]
                continue
            if opt is 'flags':
                einputs.update(inputs[opt])
                continue
            print 'option %s not supported'%(opt)
        return einputs

    def run(self, mfile=True):
        
        job = self._compile_command(mfile)

        if mfile:
            out, cmdline = mlab.run_matlab_script(job, 
                                                  script_name='pyscript_spmnormalize')
        else:
            out = run_jobdef(job)
            cmdline = ''
            
        output = InterfaceResult(provenance=Bunch(returncode=returncode,
                                                  stdout=out,stderr=err),
                                 outputs=self._aggregate_outputs(),
                                 interface=self.copy())
        return output
        
        
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        valid_inputs = self._parseinputs()
        if type(self.inputs.infile) == type([]):
            sess_scans = scans_for_fnames(self.inputs.infile)
        else:
            sess_scans = scans_for_fname(self.inputs.infile)

        # create job structure form valid options and data
        tmp = [{'data':sess_scans,
                'fwhm':valid_inputs['fwhm'],
                }]
        if mfile:
            return make_mfile('spatial','smooth',tmp)
        else:
            return make_job('spatial','smooth',tmp)

class Level1Design(CommandLine):
    """Generate an SPM design matrix

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the Level1Design.inputs attributes
    see self.inputs_help() for a list of Level1Design.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_smooth via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    Level1Design().inputs_help()


    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_fmri_design'

    def inputs_help(self):
        doc = """
            Mandatory Parameters
            --------------------
            dir : string
                directory in which to store the SPM.mat file
            timing_units : string
                units for specification of onsets or blocks
                (scans or secs) 
            interscan_interval : float (in secs)
                Interscan  interval,  TR, (specified in seconds). This
                is the time  between  acquiring  a  plane of one
                volume and the same plane  in  the  next  volume.  It
                is  assumed to be constant throughout.

            Optional Parameters
            -------------------
            (all default to None and are unset)
            microtime_resolution : float (in secs)
                The  microtime resolution, t, is the number of
                time-bins per scan used when building regressors.
                spm default = 16
            microtime_onset : float (in secs)
                The  microtime  onset, is the first time-bin at which
                the regressors  are  resampled to coincide with data
                acquisition. If  onset  =  1  then the regressors will be
                appropriate for the first   slice.   If   you  want
                to  temporally  realign  the regressors  so  that they
                match responses in the middle slice then  make  onset  =
                t/2  (assuming  there  is a negligible gap between
                volume acquisitions).
                Do not change the default settings for the above two
                parameters unless you have a long TR.
            session_info : list of dicts
                Stores session specific information

                Session parameters
                ------------------
                nscan : int
                    Number of scans in a session
                scans : list of filenames
                    A single 4D nifti file or a list of 3D nifti files
                hpf : float
                    High pass filter cutoff
                    SPM default = 128 secs
                condition_info : mat filename or list of dicts 
                    Stores condition specific information

                    MAT file contents
                    -----------------
                    If  you  have multiple conditions then entering the details a
                    condition  at  a time is very inefficient. This option can be
                    used  to  load  all  the  required information in one go. You
                    will  first  need  to  create  a  *.mat  file  containing the
                    relevant information.
         
                    This  *.mat file must include the following cell arrays (each
                    1  x  n):  names,  onsets and durations. eg. names=cell(1,5),
                    onsets=cell(1,5),          durations=cell(1,5),          then
                    names{2}='SSent-DSpeak',     onsets{2}=[3    5    19    222],
                    durations{2}=[0  0  0 0], contain the required details of the
                    second  condition. These cell arrays may be made available by
                    your  stimulus  delivery  program,  eg.  COGENT. The duration
                    vectors  can  contain  a  single  entry  if the durations are
                    identical for all events.
                                                                                                            
                    Time  and  Parametric  effects can also be included. For time
                    modulation  include  a  cell  array  (1  x n) called tmod. It
                    should  have  a  have  a  single  number in each cell. Unused
                    cells  may  contain  either  a 0 or be left empty. The number
                    specifies  the  order  of  time  modulation  from 0 = No Time
                    Modulation  to  6  = 6th Order Time Modulation. eg. tmod{3} =
                    1, modulates the 3rd condition by a linear time effect.
                                                                                                            
                    For  parametric  modulation  include a structure array, which
                    is  up  to 1 x n in size, called pmod. n must be less than or
                    equal  to  the  number of cells in the names/onsets/durations
                    cell  arrays.  The structure array pmod must have the fields:
                    name,  param and poly. Each of these fields is in turn a cell
                    array  to  allow  the  inclusion  of  one  or more parametric
                    effects  per  column  of the design. The field name must be a
                    cell  array  containing  strings.  The  field param is a cell
                    array  containing  a  vector  of  parameters.  Remember  each
                    parameter  must  be  the  same  length  as  its corresponding
                    onsets   vector.   The  field  poly  is  a  cell  array  (for
                    consistency)  with  each  cell  containing  a  single  number
                    specifying the order of the polynomial expansion from 1 to 6.
                                                                                                            
                    Note  that each condition is assigned its corresponding entry
                    in  the  structure  array  (condition 1 parametric modulators
                    are  in  pmod(1),  condition  2  parametric modulators are in
                    pmod(2),   etc.   Within   a  condition  multiple  parametric
                    modulators  are  accessed via each fields cell arrays. So for
                    condition  1,  parametric  modulator  1  would  be defined in
                    pmod(1).name{1},  pmod(1).param{1},  and  pmod(1).poly{1}.  A
                    second  parametric modulator for condition 1 would be defined
                    as  pmod(1).name{2}, pmod(1).param{2} and pmod(1).poly{2}. If
                    there  was  also a parametric modulator for condition 2, then
                    remember  the  first  modulator for that condition is in cell
                    array     1:     pmod(2).name{1},    pmod(2).param{1},    and
                    pmod(2).poly{1}.   If   some,  but  not  all  conditions  are
                    parametrically  modulated,  then the non-modulated indices in
                    the  pmod  structure  can  be  left  blank.  For  example, if
                    conditions  1  and  3 but not condition 2 are modulated, then
                    specify  pmod(1)  and pmod(3). Similarly, if conditions 1 and
                    2  are  modulated  but  there are 3 conditions overall, it is
                    only necessary for pmod to be a 1 x 2 structure array.
                                                                                                            
                    EXAMPLE:
                    Make an empty pmod structure: 
                      pmod = struct('name',{''},'param',{},'poly',{});
                    Specify one parametric regressor for the first condition: 
                      pmod(1).name{1}  = 'regressor1';
                      pmod(1).param{1} = [1 2 4 5 6];
                      pmod(1).poly{1}  = 1;
                    Specify 2 parametric regressors for the second condition: 
                      pmod(2).name{1}  = 'regressor2-1';
                      pmod(2).param{1} = [1 3 5 7]; 
                      pmod(2).poly{1}  = 1;
                      pmod(2).name{2}  = 'regressor2-2';
                      pmod(2).param{2} = [2 4 6 8 10];
                      pmod(2).poly{2}  = 1;
                                                                                                            
                    The   parametric   modulator  should  be  mean  corrected  if
                    appropriate.  Unused structure entries should have all fields
                    left empty.

                    Condition parameters
                    --------------------
                    name : string
                        Name of condition
                    onset : list of numbers
                        Onset times of each event/block
                    duration: float or list
                        Specify   the   event   durations.  Epoch  and
                        event-related responses  are  modeled  in exactly
                        the  same  way  but  by specifying their
                        different  durations. Events are specified with  a
                        duration  of 0. If you enter a single number for
                        the durations  it will be assumed that all trials
                        conform to this duration.  If you have multiple
                        different durations, then the number must match
                        the number of onset times.
                    tmod : int
                        This  option  allows  for  the
                        characterisation of linear or nonlinear  time 
                        effects.  For  example, 1st order modulation would
                        model  the  stick functions and a linear change of
                        the stick  function  heights  over  time. Higher
                        order modulation will   introduce  further
                        columns  that  contain  the  stick functions
                        scaled by time squared, time cubed etc.
                    pmod : list of dicts
                        Model  interractions  with  user  specified
                        parameters. This allows  nonlinear  effects
                        relating to some other measure to be modelled in
                        the design matrix.

                        Parametric modulator parameters
                        -------------------------------
                        name : string
                            Name of the parametric modulator
                        param : list
                            Numerical values of the parameter. One per
                            each event of the condition.
                        poly : int
                            For  example,  1st  order  modulation
                            would  model the stick functions  and  a
                            linear change of the stick function heights
                            over   different   values  of  the  parameter.
                            Higher  order modulation  will  introduce
                            further columns that contain the stick
                            functions scaled by parameter squared, cubed
                            etc.

                regressor_info : mat/txt filename or list of dicts 
                    Stores regressor specific information

                    MAT/TXT file contents
                    ---------------------
                    You  will  first  need  to  create  a *.mat file
                    containing a matrix  R  or  a  *.txt  file
                    containing the regressors. Each column  of  R
                    will  contain  a different regressor. When SPM
                    creates  the  design  matrix the regressors will
                    be named R1, R2, R3, ..etc.
 
                    Regressor parameters
                    --------------------
                    name : string
                        Name of regressor
                    val : list 
                        List of values for the regressor

            factor_info : list of dicts
                Stores factor specific information

                Factor parameters
                -----------------
                name : string
                    Name of factor (use condition name)
                levels: int
                    Number of levels for the factor

            bases : dict {'name':{'basesparam1':val,...}}
                name : string
                    Name of basis function (hrf, fourier, fourier_han,
                    gamma, fir)

                Parameters
                ----------
                hrf :
                    derivs : 2-element list
                        Model  HRF  Derivatives. The canonical HRF combined with time
                        and  dispersion derivatives comprise an 'informed' basis set,
                        as  the  shape  of  the  canonical  response  conforms to the
                        hemodynamic   response   that   is   commonly  observed.  The
                        incorporation  of  the derivate terms allow for variations in
                        subject-to-subject  and  voxel-to-voxel  responses.  The time
                        derivative  allows the peak response to vary by plus or minus
                        a  second  and  the dispersion derivative allows the width of
                        the  response  to  vary.  The  informed basis set requires an
                        SPM{F}  for  inference.  T-contrasts  over just the canonical
                        are  perfectly  valid  but  assume constant delay/dispersion.
                        The  informed  basis  set  compares  favourably  with eg. FIR
                        bases on many data sets. No derivatives: [0,0],
                        Time derivatives : [1,0], Time and Dispersion
                        derivatives: [1,1]
                fourier, fourier_han, gamma, fir:
                    length : int
                        Post-stimulus window length (in seconds)
                    order : int
                        Number of basis functions
            volterra_expansion_order : int
                Generalized convolution of inputs (U) with basis set
                (bf). Do not model interactions (1) or model
                interactions (2)
                SPM default = 1
            global_intensity_normalization : string
                Global intensity normalization (scaling or none)
                SPM default  = none
            mask_image : filename
                Specify  an  image  for  explicitly  masking  the
                analysis. 
            model_serial_correlations : string
                Serial  correlations  in  fMRI  time  series  due  to
                aliased biorhythms  and unmodelled neuronal activity
                can be accounted for  using  an  autoregressive  AR(1)
                model during Classical (ReML) parameter estimation.
                AR(1) or none
                SPM default = AR(1) 
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(dir=None,
                            timing_units=None,
                            interscan_interval=None,
                            microtime_resolution=None,
                            microtime_onset=None,
                            session_info=None,
                            factor_info=None,
                            bases=None,
                            volterra_expansion_order=None,
                            global_intensity_normalization=None,
                            mask_image=None,
                            model_serial_correlations=None,
                            flags=None)
        
    def _parseinputs(self):
        """validate spm normalize options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'dir':'','timing':{},'sess':[],'fact':{},'bases':{},
                   'volt':{},'global':{},'mask':{},'cvi':''}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'dir':
                einputs['dir'] = inputs[opt]
                continue
            if opt is 'timing_units':
                einputs['timing'].update(units=inputs[opt])
                continue
            if opt is 'interscan_interval':
                einputs['timing'].update(RT=inputs[opt])
                continue
            if opt is 'microtime_resolution':
                einputs['timing'].update(fmri_t=inputs[opt])
                continue
            if opt is 'microtime_onset':
                einputs['timing'].update(fmri_t0=inputs[opt])
                continue
            if opt is 'session_info':
                einputs['sess'] = inputs[opt]
                continue
            if opt is 'factor_info':
                einputs['fact'] = inputs[opt]
                continue
            if opt is 'bases':
                einputs['bases'] = inputs[opt]
                continue
            if opt is 'volterra_expansion_order':
                einputs['volt'] = inputs[opt]
                continue
            if opt is 'global_intensity_normalization':
                einputs['global'] = inputs[opt]
                continue
            if opt is 'mask_image':
                einputs['mask'] = inputs[opt]
                continue
            if opt is 'model_serial_correlations':
                einputs['cvi'] = inputs[opt]
                continue
            if opt is 'flags':
                einputs.update(inputs[opt])
                continue
            print 'option %s not supported'%(opt)
        return einputs

    def run(self, mfile=True):
        
        job = self._compile_command(mfile)

        if mfile:
            out, cmdline = mlab.run_matlab_script(job, 
                                                  script_name='pyscript_spmnormalize')
        else:
            out = run_jobdef(job)
            cmdline = ''
            
        output = InterfaceResult(provenance=Bunch(returncode=returncode,
                                                  stdout=out,stderr=err),
                                 outputs=self._aggregate_outputs(),
                                 interface=self.copy())
        return output
        
        
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        valid_inputs = self._parseinputs()

        # create job structure form valid options and data
        tmp = [{'dir':valid_inputs['dir'],
                'timing':valid_inputs['timing'],
                'sess':valid_inputs['sess'],
                'fact':valid_inputs['factors'],
                'bases':valid_inputs['bases'],
                'volt':valid_inputs['volt'],
                'global':valid_inputs['global'],
                'mask':valid_inputs['mask'],
                'cvi':valid_inputs['cvi']
                }]
        if mfile:
            return make_mfile('stats','fmri_spec',tmp)
        else:
            return make_job('stats','fmri_spec',tmp)
        

class EstimateModel(CommandLine):
    """use spm_spm to estimate the parameters of a model

    Parameters
    ----------
    inputs : mapping 
    key, value pairs that will update the EstimateModel.inputs attributes
    see self.inputs_help() for a list of EstimateModel.inputs attributes
    
    Attributes
    ----------
    inputs : Bunch
    a (dictionary-like) bunch of options that can be passed to 
    spm_spm via a job structure
    cmdline : string
    string used to call matlab/spm via CommandLine interface
    
    

    Options
    -------

    To see optional arguments
    EstimateModel().inputs_help()


    Examples
    --------
    
    """
    
    @property
    def cmd(self):
        return 'spm_spm'

    def inputs_help(self):
        doc = """
            Mandatory Parameters
            --------------------
            spm_design_file : filename
                Filename containing absolute path to SPM.mat
            estimation_method: dict
                There  are  three  possible  estimation  procedures  for fMRI
                models  (1)  classical  (ReML)  estimation of first or second
                level  models,  (2) Bayesian estimation of first level models
                and  (3)  Bayesian  estimation of second level models. Option
                (2)  uses  a  Variational Bayes (VB) algorithm that is new to
                SPM5.  Option  (3)  uses  the  Empirical Bayes algorithm with
                global shrinkage priors that was also in SPM2.

                Options
                -------
                {'Classical': 1}
                    Model  parameters  are  estimated  using  Restricted  Maximum
                    Likelihood   (ReML).   This  assumes  the  error  correlation
                    structure  is the same at each voxel.
                {'Bayesian2': 1}
                    Bayesian  estimation  of  2nd  level models. This option uses
                    the  Empirical  Bayes  algorithm with global shrinkage priors
                    that  was  previously  implemented in SPM2. Use of the global
                    shrinkage  prior  embodies  a  prior  belief that, on average
                    over  all  voxels,  there is no net experimental effect. Some
                    voxels  will  respond  negatively  and some positively with a
                    variability  determined  by  the  prior precision. This prior
                    precision  can  be  estimated  from  the data using Empirical
                    Bayes.
                {'Bayesian' : dict}
                    Model  parameters are estimated using Variational Bayes (VB).
                    This  allows  you  to  specify  spatial priors for regression
                    coefficients  and  regularised  voxel-wise  AR(P)  models for
                    fMRI   noise   processes.  The  algorithm  does  not  require
                    functional  images  to be spatially smoothed. Estimation will
                    take  about  5 times longer than with the classical approach.
                    This is why VB is not the default estimation option.
                 USE IF YOU KNOW HOW TO SPECIFY PARAMETERS
            flags : USE AT OWN RISK
                #eg:'flags':{'eoptions':{'suboption':value}}
            """
        print doc

    def _populate_inputs(self):
        self.inputs = Bunch(spm_design_file=None,
                            estimation_method=None,
                            flags=None)
        
    def _parseinputs(self):
        """validate spm normalize options
        if set to None ignore
        """
        out_inputs = []
        inputs = {}
        einputs = {'spmmat':'','method':{}}

        [inputs.update({k:v}) for k, v in self.inputs.iteritems() if v is not None ]
        for opt in inputs:
            if opt is 'spm_design_file':
                einputs['spmmat'] = inputs[opt]
                continue
            if opt is 'estimation_method':
                einputs['method'].update(inputs[opt])
                continue
            if opt is 'flags':
                einputs.update(inputs[opt])
                continue
            print 'option %s not supported'%(opt)
        return einputs

    def _aggregate_outputs(self):
        cwd = os.path.abspath(self.inputs.get('cwd','.'))
        outputs = Bunch(mask_image=None,
                        beta_images=None,
                        residual_mean_square_image=None,
                        RPVimage=None)

    def run(self, mfile=True):
        
        job = self._compile_command(mfile)

        if mfile:
            out, cmdline = mlab.run_matlab_script(job, 
                                                  script_name='pyscript_spmnormalize')
        else:
            out = run_jobdef(job)
            cmdline = ''
            
        output = InterfaceResult(provenance=Bunch(returncode=returncode,
                                                  stdout=out,stderr=err),
                                 outputs=self._aggregate_outputs(),
                                 interface=self.copy())
        return output
        
    def _compile_command(self,mfile=True):
        """validates spm options and generates job structure
        if mfile is True uses matlab .m file
        else generates a job structure and saves in .mat
        """
        valid_inputs = self._parseinputs()
        # create job structure form valid options and data
        tmp = [valid_inputs]
        if mfile:
            return make_mfile('stats','fmri_est',tmp)
        else:
            return make_job('stats','fmri_est',tmp)
